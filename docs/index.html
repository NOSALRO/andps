<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Primary Meta Tags -->
  <title>Autonomous Neural Dynamic Policies (ANDPs) Paper Website</title>
  <meta name="title" content="Autonomous Neural Dynamic Policies (ANDPs) Paper Website" />
  <meta name="description" content="Website of the paper " Sensorimotor Learning with Stability Guarantees via
    Autonomous Neural Dynamic Policies"" />

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://nosalro.github.io/andps_website/" />
  <meta property="og:title" content="Autonomous Neural Dynamic Policies (ANDPs) Paper Website" />
  <meta property="og:description" content="Website of the paper " Sensorimotor Learning with Stability Guarantees via
    Autonomous Neural Dynamic Policies"" />
  <meta property="og:image"
    content="https://nosalro.github.io/andps_website/static/images/concept_figure_banner.png" />

  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image" />
  <meta property="twitter:url" content="https://nosalro.github.io/andps_website/" />
  <meta property="twitter:title" content="Autonomous Neural Dynamic Policies (ANDPs) Paper Website" />
  <meta property="twitter:description" content="Website of the paper " Sensorimotor Learning with Stability Guarantees
    via Autonomous Neural Dynamic Policies"" />
  <meta property="twitter:image"
    content="https://nosalro.github.io/andps_website/static/images/concept_figure_banner.png" />


  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords"
    content="Autonomous Neural Dynamic Policies, ANDPs, sensorimotor learning, robotics, neural networks, dynamical systems, stable learning, flexible learning, artificial intelligence, robotics research">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ANDPs Website</title>
  <link rel="icon" type="image/x-icon"
    href="https://github.com/NOSALRO/nosalro.github.io/blob/main/src/images/nosalro_logov1.jpg?raw=true">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="static/css/bibtex.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

  <!-- Title Authors Links -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Sensorimotor Learning with Stability Guarantees via Autonomous
              Neural Dynamic Policies</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://dtotsila.github.io/" target="_blank">Dionis Totsila</a><sup>*1</sup>,</span>
              <span class="author-block">
                <a href="https://costashatz.github.io/" target="_blank">Konstantinos
                  Chatzilygeroudis</a><sup>*2</sup>,</span>
              <span class="author-block">
                <a href="https://rpl-as-ucl.github.io/people/" target="_blank">Valerio Modugno</a><sup>3</sup>
              </span>
              <span class="author-block">
                <a href="https://dennisushi.github.io/" target="_blank">Denis Hadjivelichkov</a><sup>3</sup>
              </span>
              <span class="author-block">
                <a href="https://dkanou.github.io/" target="_blank">Dimitrios Kanoulas</a><sup>3,4</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"> <sup>1</sup>Inria, CNRS, Loria and Universite de Lorraine,
                France.<br>
                <sup>2</sup>Computational Intelligence Laboratory (CILab), Department of Mathematics, University of
                Patras and Laboratory of Automation and Robotics (LAR), Department of Electrical and Computer
                Engineering. University of Patras, Greece.<br>
                <sup>3</sup>Robot Perception and Learning Lab (RPL Lab), Department of Computer Science, University
                College London (UCL), United Kingdom. <br>
                <sup>4</sup>Archimedes/Athena RC, Greece.<br>
                <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                <br>Submitted to IEEE Robotics and Automation Letters (RA-L) 2024</span>

            </div>

            <div class="column has-text-centered">
              <!-- <div class="publication-links"> -->
              <!-- Arxiv PDF link -->
              <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

              <!-- Supplementary PDF link -->
              <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/NOSALRO/andps" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <!-- ArXiv abstract Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2305.12886" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>
  <!-- End Title Authors Links -->

  <!-- Concept Figure-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="static/images/concept_figure.png" alt="ANDPs Pipeline" style="width:50%; margin-left: 25%;">
        <h2 class="subtitle has-text-centered">
          ANDPs Pipeline Overview.
        </h2>
      </div>
    </div>
  </section>
  <!-- End Concept Figure -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              State-of-the-art sensorimotor learning algorithms, either in the context of reinforcement learning or
              imitation learning, offer policies that can often produce unstable behaviors, damaging the robot and/or
              the environment. Moreover, it is very difficult to interpret the optimized controller and analyze its
              behavior and/or performance. Traditional robot learning, on the contrary, relies on dynamical system-based
              policies that can be analyzed for stability/safety. Such policies, however, are neither flexible nor
              generic and usually work only with proprioceptive sensor states. In this work, we bridge the gap between
              generic neural network policies and dynamical system-based policies, and we introduce Autonomous Neural
              Dynamic Policies (ANDPs) that: (a) are based on autonomous dynamical systems, (b) always produce
              asymptotically stable behaviors, and (c) are more flexible than traditional stable dynamical system-based
              policies. ANDPs are fully differentiable, flexible generic-policies that can be used for both imitation
              learning and reinforcement learning setups, while ensuring asymptotic stability. Through several
              experiments, we explore the flexibility and capacity of ANDPs in several imitation learning tasks
              including experiments with image observations. The results show that ANDPs combine the benefits of both
              neural network-based and dynamical system-based methods.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->



  <!-- Youtube video -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <h2 class="title is-3">Video Presentation</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">

            <div class="publication-video" style="width: 80%; margin-left:10%">
              <!-- Youtube embed code here -->
              <iframe width="560" height="315" src="https://www.youtube.com/embed/ZI9-TLSovpQ?si=fx_VrUImCKwN0uts"
                title="YouTube video player" frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End youtube video -->


  <!-- Experiment 1 carousel -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Experiment 1: Imitating 2D Trajectories</h2>
        <div class="hero-body">
          <h2 class="subtitle has-text-centered">
            Experiment 1 Pipeline overview
          </h2>
          <img src="static/images/exp_1.png" alt="ANDPs Pipeline" style="width: 50%; margin-left: 25%;">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">

              <h2 class="subtitle has-text-centered">
                Qualitative results for ANDPs, SEDS, and NNs in 4 selected tasks of the LASA dataset.
              </h2>
              <img src="static/images/lasa_qualitative.png" alt="comparisons lasa qualitative" />

            </div>
            <div class="item">

              <h2 class="subtitle has-text-centered">
                Training and Test set errors on selected tasks for the quantitative comparison of ANDPs with SEDS and
                NNs.
              </h2>
              <img src="static/images/train_errors_final.png" alt="errors lasa quantitative" height="50%" />

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End Experiment 1 carousel -->

  <!-- Experiment 2 carousels -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Experiment 2: Imitating Robotic Behaviors</h2>

        <section class="hero teaser">
          <div class="container is-max-desktop">
            <div class="hero-body">
              <h2 class="subtitle has-text-centered">
                Experiment 2 Pipeline overview
              </h2>
              <img src="static/images/exp_2_overview.png" alt="ANDPs Pipeline" style="width: 50%; margin-left: 25%;">

              <div id="demo-carousel" class="carousel results-carousel">
                <div class="item item-video1">

                  <h2 class="subtitle has-text-centered">
                    Multi-Task Learning with Image Input Demonstrations
                  </h2>
                  <video poster="" id="video1" autoplay controls muted loop height="100%">

                    <source src="static/videos/demos.mp4" type="video/mp4">
                </div>
                <div class="item is-centered">

                  <h2 class="subtitle has-text-centered">
                    Multi-task scenario with image inputs. All tasks are learned with a single model that can
                    distinguish between tasks given an image input
                  </h2>
                  <img src="static/images/andps_multi_task_images.png" alt="Multi-Task qualitative" height="100%" />

                </div>

              </div>
            </div>

        </section>
      </div>

    </div>

    <div class="hero-body">
      <div class="container">
        <!-- <h2 class="title is-4"></h2> -->
        <div id="demo-carousel" class="carousel results-carousel">

          <div class="item">
            <h2 class="subtitle has-text-centered">
              Comparison of ANDPS with a simple CNN-based policy to reactiveness of changes in the
              non-controllable part of the state, we switch from the line image to the sine image at t=1s.
            </h2>
            <img src="static/images/andps_cnn_reactiveness.png" alt="andps reactiveness" height="100%" />
          </div>
          <!-- Split the div into a left and a right div for each video -->

          <div style="display: flex; justify-content: center;">
            <div style="display: flex; flex-direction: column; align-items: center;">
              <video poster="" id="video2" autoplay controls muted loop style="width: 50%;">
                <source src="static/videos/andps_reactiveness.mp4" type="video/mp4">
              </video>
              <h2 class="subtitle has-text-centered" style="font-weight: bolder;">
                ANDPS
              </h2>
            </div>

            <div style="display: flex; flex-direction: column; align-items: center;">
              <video poster="" id="video3" autoplay controls muted loop style="width: 50%;">
                <source src="static/videos/cnn_reactivenss.mp4" type="video/mp4">
              </video>
              <h2 class="subtitle has-text-centered" style="font-weight: bolder;">
                Simple CNN
              </h2>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="hero-body">
      <div class="container">
        <!-- <h2 class="title is-4"></h2> -->
        <div id="demo-carousel" class="carousel results-carousel">

          <div class="item">
            <h2 class="subtitle has-text-centered">
              Comparison of the reactiveness of ANDPs and simple CNNs to external force perturbations. We apply an
              external force twice: at t=0s and $t=4s.
            </h2>
            <img src="static/images/andps_cnn_robustness.png" alt="andps reactiveness" height="100%" />
          </div>
          <!-- Split the div into a left and a right div for each video -->

          <div style="display: flex; justify-content: center;">
            <div style="display: flex; flex-direction: column; align-items: center;">
              <video poster="" id="video2" autoplay controls muted loop style="width: 50%;">
                <source src="static/videos/andps_robustness.mp4" type="video/mp4">
              </video>
              <h2 class="subtitle has-text-centered" style="font-weight: bolder;">
                ANDPS
              </h2>
            </div>

            <div style="display: flex; flex-direction: column; align-items: center;">
              <video poster="" id="video3" autoplay controls muted loop style="width: 50%;">
                <source src="static/videos/cnn_robustness.mp4" type="video/mp4">
              </video>
              <h2 class="subtitle has-text-centered" style="font-weight: bolder;">
                Simple CNN
              </h2>
            </div>

          </div>
          <div class="item">
            <h2 class="subtitle has-text-centered">
              Comparison of ANDPs with a simple CNN based policy to i.i.d Gaussian noise application at every time step.
            </h2>
            <img src="static/images/andps_cnn_robustness_noise.png" alt="andps reactiveness" height="100%" />
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- End Experiment 2 carousels -->

  <!-- Experiment 3 carousel -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Experiment 3: Fixed Base Robot - Pouring Task</h2>
        <div class="hero-body">
          <h2 class="subtitle has-text-centered">
            Experiment 3 Pipeline overview
          </h2>
          <img src="static/images/exp_3.png" alt="ANDPs Pipeline" style="width: 50%; margin-left: 25%;">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-video4">

              <h2 class="subtitle has-text-centered">
                Data Collection
              </h2>
              <video poster="" id="video4" autoplay controls muted loop width="80%">

                <source src="static/videos/pour_blurred.mp4" type="video/mp4">
            </div>

            <div class="item item-video5">
              <h2 class="subtitle has-text-centered">
                Resulting Behavior
              </h2>

              <video poster="" id="video4" autoplay controls muted loop width="80%">

                <source src="static/videos/pour.mp4" type="video/mp4">
            </div>
            <div class="item ">

              <h2 class="subtitle has-text-centered">
                Results
              </h2>
              <img src="static/images/pour_box_plor.png" alt="ANDPs Pipeline" style="width:80%; margin-left: 10%;">
            </div>
          </div>

        </div>
      </div>
    </div>
    </div>
  </section>
  <!-- End Experiment 3 carousel -->


  <!-- Experiment 4  -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Experiment 4: Floating Base Robot - Follow the Line</h2>
        <div class="hero-body">
          <h2 class="subtitle has-text-centered">
            Experiment 4 Pipeline overview
          </h2>
          <img src="static/images/exp_4.png" alt="ANDPs Pipeline" style="width: 50%; margin-left: 25%;">
          <div id="results-carousel" class="carousel results-carousel">

            <div class="item item-video5">
              <h2 class="subtitle has-text-centered">
                Resulting Behavior
              </h2>

              <video poster="" id="video4" autoplay controls muted loop width="80%">

                <source src="static/videos/go1_2.mp4" type="video/mp4">
            </div>
            <div class="item ">

              <h2 class="subtitle has-text-centered">
                Results
              </h2>
              <img src="static/images/go_1_trajectories_v2-1.png" alt="ANDPs Pipeline" style="height:100%;">
            </div>
          </div>

        </div>
      </div>
    </div>
    </div>
  </section>
  <!-- End Experiment 3 carousel -->

  <!-- Paper poster -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h3 class="postertext">Part of the paper was presented at 2023 ICRA <a
            href="https://life-long-learning-with-human-help-l3h2.github.io/" target="_blank">Life-Long Learrning with
            Human Help (L3H2) Workshop</a> (Non-archival). You can find the poster <a
            href="static/pdfs/2023-ICRA-L3H2-Poster-ANDPs.pdf" target="_blank">here</a>.</h3>
      </div>
    </div>
  </section>
  <!--End paper poster -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
  <span class="keyword">@article</span>{dionis2024andps,
  <span class="keyword">title</span>={{<span class="string">Sensorimotor Learning with Stability Guarantees via Autonomous Neural Dynamic Policies</span>}},
  <span class="keyword">author</span>={<span class="string">Totsila, Dionis and Chatzilygeroudis, Konstantinos and Modugno, Valerio and Hadjivelichkov, Denis and Kanoulas, Dimitrios</span>},
  <span class="keyword">year</span>={<span class="string">2024</span>},
  <span class="keyword">journal</span>={{<span class="string">Preprint</span>}}
  </code></pre>

    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <h2 class="title is-4">Acknowledgements</h2>
            Konstantinos Chatzilygeroudis was supported by the <a href="https://www.elidek.gr/en/homepage/"
              target="_blank"> Hellenic Foundation for Research and Innovation </a>
            (H.F.R.I.) under the "3rd Call for H.F.R.I. Research Projects to support Post-Doctoral Researchers" (Project
            Acronym: <a href="https://nosalro.github.io/" target="_blank"> NOSALRO</a> Project Number: 7541). Dimitrios
            Kanoulas and Valerio Modugno were supported by the UKRI
            Future Leaders Fellowship [MR/V025333/1] (RoboHike)
            <div style="display: flex; justify-content: center;">
              <table>
                <tr>
                  <td style="text-align: center;">
                    <img
                      src="https://camo.githubusercontent.com/f8bb37f574681aaa8d882bafab454672602aaceb179d19bd6910cf1470b31e01/68747470733a2f2f7777772e656c6964656b2e67722f77702d636f6e74656e742f7468656d65732f656c6964656b2f696d616765732f656c6964656b5f6c6f676f5f656e2e706e67"
                      alt="your_image1" style="width:100%">
                  </td>
                  <td style="text-align: center;">
                    <img
                      src="https://camo.githubusercontent.com/c9dca94747622e29f18405f237e695f282c0f238fbff78fa206c6208d37cdc58/68747470733a2f2f7777772e63696e756b2e6f72672f636f6e74656e742f75706c6f6164732f323032322f31312f554b52492d6c6f676f322e706e67"
                      alt="your_image2" style="width:30%">
                  </td>
                </tr>
              </table>
            </div>
            <br>
            This work was conducted as collaboration of the <a href=" http://cilab.math.upatras.gr/" target="_blank">
              Computational Intelligence Lab</a> (CILab), Department of
            Mathematics, University of Patras, Greece, and the <a href="https://rpl-as-ucl.github.io/"
              target="_blank">Robot Perception and Learning Lab</a> (RPL Lab), Department
            of Computer Science, University College London (UCL), United Kingdom.
            <!-- now we will add 6 images on the same row -->

            <div style="text-align: center;">
              <div class="row">
                <div class="column">
                  <img
                    src="https://camo.githubusercontent.com/580a8077056cd30a4e2314833a47ad8163bd04d4f166822c6442c6c5975fcf8c/68747470733a2f2f6e6f73616c726f2e6769746875622e696f2f696d616765732f6c6f676f5f63696c61622e6a7067"
                    alt="your_image1" style="width:25%">
                </div>
                <div class="column">
                  <img
                    src="https://camo.githubusercontent.com/470201412e4dd5bf4931ee5284b9d101c292204643f85e82cc3382e1e7ca34bb/68747470733a2f2f7777772e757061747261732e67722f77702d636f6e74656e742f75706c6f6164732f75705f323031375f6c6f676f5f656e2e706e67"
                    alt="your_image2" style="width:25%">
                </div>
                <div class="column">
                  <img
                    src="https://camo.githubusercontent.com/27c988cb897600fe07a16d22a657edf5dfa0a0e9b923b7d4ed6cfebbdc75005f/68747470733a2f2f72706c2d61732d75636c2e6769746875622e696f2f696d616765732f6c6f676f732f72706c2d63732d75636c2d6c6f676f2e706e67"
                    alt="your_image3" style="width:25%">
                </div>
              </div>
            </div>


            <hr style="border-top: 1px dotted #8c8b8b;">
            <div class="content">

              <p>
                <br>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic
                  Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io"
                  target="_blank">Nerfies</a> project page.
                You are free to borrow the of this website, we just ask that you link back to this page in the
                footer.


                <br> This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>

            </div>
          </div>
        </div>
      </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>